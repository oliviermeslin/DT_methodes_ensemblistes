<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>cart – Introduction aux méthodes ensemblistes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter2/2-bagging.html" rel="next">
<link href="../../chapters/chapter2/0-intro.html" rel="prev">
<link href="../../images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter2/0-intro.html">Présentation formelle des algorithmes</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter2/1-CART.html">La brique élémentaire: l’arbre de décision</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Introduction aux méthodes ensemblistes</a> 
        <div class="sidebar-tools-main">
    <a href="../.././pdf/dt_methodes_ensemblistes.pdf" title="NMFS Open Science" class="quarto-navigation-tool px-1" aria-label="NMFS Open Science"><i class="bi bi-file-pdf-fill"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction aux méthodes ensemblistes</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter1/0-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Survol des méthodes ensemblistes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter1/1-survol.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Que sont les méthodes ensemblistes?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter1/2-comparaison_GB_RF.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comparaison RF-GBDT</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter2/0-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Présentation formelle des algorithmes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/1-CART.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">La brique élémentaire: l’arbre de décision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/2-bagging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Le bagging</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/3-random_forest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">La forêt aléatoire</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/4-boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Le <em>boosting</em></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter3/0-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comment bien utiliser les algorithmes?</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/1-guide_usage_RF.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guide d’entraînement des forêts aléatoires</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#la-brique-élémentaire-larbre-de-décision" id="toc-la-brique-élémentaire-larbre-de-décision" class="nav-link active" data-scroll-target="#la-brique-élémentaire-larbre-de-décision">La brique élémentaire: l’arbre de décision</a>
  <ul class="collapse">
  <li><a href="#le-principe-fondamental-partitionner-pour-prédire" id="toc-le-principe-fondamental-partitionner-pour-prédire" class="nav-link" data-scroll-target="#le-principe-fondamental-partitionner-pour-prédire">Le principe fondamental : partitionner pour prédire</a>
  <ul class="collapse">
  <li><a href="#les-défis-du-partitionnement-optimal" id="toc-les-défis-du-partitionnement-optimal" class="nav-link" data-scroll-target="#les-défis-du-partitionnement-optimal">Les défis du partitionnement optimal</a></li>
  <li><a href="#les-solutions-apportées-par-les-arbres-de-décision" id="toc-les-solutions-apportées-par-les-arbres-de-décision" class="nav-link" data-scroll-target="#les-solutions-apportées-par-les-arbres-de-décision">Les solutions apportées par les arbres de décision</a></li>
  <li><a href="#terminologie-et-structure-dun-arbre-de-décision" id="toc-terminologie-et-structure-dun-arbre-de-décision" class="nav-link" data-scroll-target="#terminologie-et-structure-dun-arbre-de-décision">Terminologie et structure d’un arbre de décision</a></li>
  <li><a href="#illustration" id="toc-illustration" class="nav-link" data-scroll-target="#illustration">Illustration</a></li>
  </ul></li>
  <li><a href="#lalgorithme-cart-un-partitionnement-binaire-récursif" id="toc-lalgorithme-cart-un-partitionnement-binaire-récursif" class="nav-link" data-scroll-target="#lalgorithme-cart-un-partitionnement-binaire-récursif">L’algorithme CART, un partitionnement binaire récursif</a>
  <ul class="collapse">
  <li><a href="#définir-une-fonction-dimpureté-adaptée-au-problème" id="toc-définir-une-fonction-dimpureté-adaptée-au-problème" class="nav-link" data-scroll-target="#définir-une-fonction-dimpureté-adaptée-au-problème">Définir une fonction d’impureté adaptée au problème</a></li>
  <li><a href="#identifier-la-partition-binaire-maximisant-la-réduction-de-limpureté" id="toc-identifier-la-partition-binaire-maximisant-la-réduction-de-limpureté" class="nav-link" data-scroll-target="#identifier-la-partition-binaire-maximisant-la-réduction-de-limpureté">Identifier la partition binaire maximisant la réduction de l’impureté</a></li>
  <li><a href="#réitérer-le-processus-jusquà-atteindre-un-critère-darrêt" id="toc-réitérer-le-processus-jusquà-atteindre-un-critère-darrêt" class="nav-link" data-scroll-target="#réitérer-le-processus-jusquà-atteindre-un-critère-darrêt">Réitérer le processus jusqu’à atteindre un critère d’arrêt</a></li>
  <li><a href="#elagage-pruning" id="toc-elagage-pruning" class="nav-link" data-scroll-target="#elagage-pruning">Elagage (<em>pruning</em>)</a></li>
  <li><a href="#prédire" id="toc-prédire" class="nav-link" data-scroll-target="#prédire">Prédire</a></li>
  <li><a href="#critères-de-qualité-et-ajustements" id="toc-critères-de-qualité-et-ajustements" class="nav-link" data-scroll-target="#critères-de-qualité-et-ajustements">Critères de qualité et ajustements</a></li>
  </ul></li>
  <li><a href="#avantages-et-limites-de-cette-approche" id="toc-avantages-et-limites-de-cette-approche" class="nav-link" data-scroll-target="#avantages-et-limites-de-cette-approche">Avantages et limites de cette approche</a>
  <ul class="collapse">
  <li><a href="#avantages" id="toc-avantages" class="nav-link" data-scroll-target="#avantages">Avantages</a></li>
  <li><a href="#limites" id="toc-limites" class="nav-link" data-scroll-target="#limites">Limites</a></li>
  </ul></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/oliviermeslin/DT_methodes_ensemblistes/edit/main/chapters/chapter2/1-CART.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/oliviermeslin/DT_methodes_ensemblistes/blob/main/chapters/chapter2/1-CART.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/oliviermeslin/DT_methodes_ensemblistes/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="1-CART.pdf"><i class="bi bi-file-pdf"></i>Typst</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">




<section id="la-brique-élémentaire-larbre-de-décision" class="level1">
<h1>La brique élémentaire: l’arbre de décision</h1>
<p>Les arbres de décision sont des outils puissants en apprentissage automatique, utilisés pour des tâches de classification et de régression. Ces algorithmes non paramétriques consistent à diviser l’espace des caractéristiques en sous-ensembles homogènes à l’aide de règles simples, afin de faire des prédictions. Malgré leur simplicité apparente, les arbres de décision sont capable de saisir des relations complexes et non linéaires entre les variables (ou <em>caractéristiques</em>) d’un jeu de données.</p>
<section id="le-principe-fondamental-partitionner-pour-prédire" class="level2">
<h2 class="anchored" data-anchor-id="le-principe-fondamental-partitionner-pour-prédire">Le principe fondamental : partitionner pour prédire</h2>
<p>Imaginez que vous souhaitiez prédire le prix d’une maison en fonction de sa superficie et de son nombre de pièces. L’espace des caractéristiques (superficie et nombre de pièces) est vaste, et les prix des maisons (la <em>réponse</em> à prédire) sont très variables. Pour prédire le prix des maisons, l’idée est de diviser cet espace en zones plus petites, où les maisons ont des prix similaires, et d’attribuer une prédiction identique à toutes les maisons situées dans la même zone.</p>
<section id="les-défis-du-partitionnement-optimal" class="level3">
<h3 class="anchored" data-anchor-id="les-défis-du-partitionnement-optimal">Les défis du partitionnement optimal</h3>
<p>L’objectif principal est de trouver la partition de l’espace des caractéristiques qui offre les meilleures prédictions possibles. Cependant, cet objectif se heurte à plusieurs difficultés, et la complexité du problème augmente rapidement avec le nombre de caractéristiques et la taille de l’échantillon:</p>
<ol type="1">
<li><strong>Infinité des découpages possibles</strong> : Il existe une infinité de façons de diviser l’espace des caractéristiques.</li>
<li><strong>Complexité de la paramétrisation</strong> : Il est difficile de représenter tous ces découpages avec un nombre limité de paramètres.</li>
<li><strong>Optimisation complexe</strong> : Même avec une paramétrisation, trouver le meilleur découpage nécessite une optimisation complexe, souvent irréaliste en pratique.</li>
</ol>
</section>
<section id="les-solutions-apportées-par-les-arbres-de-décision" class="level3">
<h3 class="anchored" data-anchor-id="les-solutions-apportées-par-les-arbres-de-décision">Les solutions apportées par les arbres de décision</h3>
<p>Pour surmonter ces difficultés, les méthodes d’arbres de décision, et notamment la plus célèbre, l’algorithme CART (Classication And Regression Tree, <span class="citation" data-cites="breiman1984cart">Breiman et al. (<a href="#ref-breiman1984cart" role="doc-biblioref">1984</a>)</span>), adoptent deux approches clés :</p>
<ol type="1">
<li><strong>Simplification du partitionnement de l’espace</strong></li>
</ol>
<p>Au lieu d’explorer tous les découpages possibles, les arbres de décision partitionnent l’espace des caractéristiques en plusieurs régions distinctes (non chevauchantes) en appliquant des règles de décision simples. Les règles suivantes sont communément adoptées:</p>
<ul>
<li><p><strong>Découpages binaires simples</strong> : À chaque étape, l’algorithme divise une région de l’espace en deux sous-régions en se basant sur une seule caractéristique (ou <em>variable</em>) et en définissant un seul seuil (ou <em>critère</em>) pour cette segmentation. Concrètement, cela revient à poser une question du type : “La valeur de la caractéristique X dépasse-t-elle un certain seuil ?” Par exemple : “La superficie de la maison est-elle supérieure à 100 m² ?”. Les deux réponses possibles (“Oui” ou “Non”) génèrent deux nouvelles sous-régions distinctes de l’espace, chacune correspondant à un sous-ensemble de données plus homogène.</p></li>
<li><p><strong>Prédictions locales</strong> : Lorsque l’algorithme s’arrête, une prédiction simple est faite dans chaque région. Il s’agit souvent de la moyenne des valeurs cibles dans cette région (régression) ou de la classe majoritaire (classification).</p></li>
</ul>
<p>Ces règles de découpage rendent le problème d’optimisation plus simple mais également plus interprétable.</p>
<ol start="2" type="1">
<li><strong>Optimisation gloutonne (<strong>greedy</strong>)</strong></li>
</ol>
<p>Plutôt que d’optimiser toutes les divisions simultanément, les arbres de décision utilisent une approche simplifiée, récursive et séquentielle :</p>
<ul>
<li><strong>Division étape par étape</strong> : À chaque étape, l’arbre choisit la meilleure division possible sur la base d’un critère de réduction de l’hétérogénéité intra-région. En revanche, il ne prend pas en compte les étapes d’optimisation futures.</li>
<li><strong>Critère local</strong> : La décision est basée sur la réduction immédiate de l’impureté ou de l’erreur de prédiction (par exemple, la réduction de la variance pour la régression). Ce processus est répété pour chaque sous-région, ce qui permet d’affiner progressivement la partition de l’espace en fonction des caractéristiques les plus discriminantes.</li>
</ul>
<p>Cette méthode dite “gloutonne” (<em>greedy</em>) s’avère efficace pour construire un partitionnement de l’espace des caractéristiques, car elle décompose un problème d’optimisation complexe en une succession de problèmes plus simples et plus rapides à résoudre. Le résultat obtenu n’est pas nécessairement un optimum global, mais il s’en approche raisonnablement et surtout rapidement.</p>
<p>Le terme “arbre de décision” provient de la structure descendante en forme d’arbre inversé qui émerge lorsqu’on utilise un algorithme glouton pour découper l’espace des caractéristiques en sous-ensemble de réponses homogènes de manière récursive. A chaque étape, deux nouvelles branches sont créées et forment une nouvelle partition de l’espace des caractéristiques.</p>
<p>Une fois entraîné, un arbre de décision est une fonction <strong>constante par morceaux</strong> défini sur l’espace des caractéristiques. En raison de leur nature <strong>non-continue</strong> et <strong>non-différentiable</strong>, il est impossible d’utiliser des méthodes d’optimisation classiques reposant sur le calcul de gradients.</p>
</section>
<section id="terminologie-et-structure-dun-arbre-de-décision" class="level3">
<h3 class="anchored" data-anchor-id="terminologie-et-structure-dun-arbre-de-décision">Terminologie et structure d’un arbre de décision</h3>
<p>Nous présentons la structure d’un arbre de décision et les principaux éléments qui le composent.</p>
<ul>
<li><p><strong>Nœud Racine (Root Node)</strong> : Le nœud racine est le point de départ de l’arbre de décision, il est situé au sommet de l’arbre. Il contient l’ensemble des données d’entraînement avant toute division. À ce niveau, l’algorithme cherche la caractéristique la plus discriminante, c’est-à-dire celle qui permet de diviser les données de manière à optimiser une fonction de perte (comme l’indice de Gini pour la classification ou la variance pour la régression).</p></li>
<li><p><strong>Nœuds Internes (Internal Nodes)</strong> : Les nœuds internes sont les points intermédiaires où l’algorithme CART applique des règles de décision pour diviser les données en sous-ensembles plus petits. Chaque nœud interne représente une question ou condition basée sur une caractéristique particulière (par exemple, “La superficie de la maison est-elle supérieure à 100 m² ?”). À chaque étape, une seule caractéristique (la superficie) et un seul seuil (supérieur à 100) sont utilisés pour faire la division.</p></li>
<li><p><strong>Branches</strong>: Les branches sont les connexions entre les nœuds, elles illustrent le chemin que les données suivent en fonction des réponses aux questions posées dans les nœuds internes. Chaque branche correspond à une décision binaire, “Oui” ou “Non”, qui oriente les observations vers une nouvelle subdivision de l’espace des caractéristiques.</p></li>
<li><p><strong>Nœuds Terminaux ou Feuilles (Leaf Nodes ou Terminal Nodes)</strong> : Les nœuds terminaux, situés à l’extrémité des branches, sont les points où le processus de division s’arrête. Ils fournissent la prédiction finale.</p>
<ul>
<li>En <strong>classification</strong>, chaque feuille correspond à une classe prédite (par exemple, “Oui” ou “Non”).</li>
<li>En <strong>régression</strong>, chaque feuille fournit une valeur numérique prédite (comme le prix estimé d’une maison).</li>
</ul></li>
</ul>
<p><em>Figure illustrative</em> : Une représentation visuelle de la structure de l’arbre peut être utile ici pour illustrer les concepts de nœuds, branches et feuilles.</p>
</section>
<section id="illustration" class="level3">
<h3 class="anchored" data-anchor-id="illustration">Illustration</h3>
<p>Supposons que nous souhaitions prédire le prix d’une maison en fonction de sa superficie et de son nombre de pièces. Un arbre de décision pourrait procéder ainsi :</p>
<ol type="1">
<li><strong>Première division</strong> : “La superficie de la maison est-elle supérieure à 100 m² ?”
<ul>
<li>Oui : Aller à la branche de gauche.</li>
<li>Non : Aller à la branche de droite.</li>
</ul></li>
<li><strong>Deuxième division (branche de gauche)</strong> : “Le nombre de pièces est-il supérieur à 4 ?”
<ul>
<li>Oui : Prix élevé (par exemple, plus de 300 000 €).</li>
<li>Non : Prix moyen (par exemple, entre 200 000 € et 300 000 €).</li>
</ul></li>
<li><strong>Deuxième division (branche de droite)</strong> : “Le nombre de pièces est-il supérieur à 2 ?”
<ul>
<li>Oui : Prix moyen (par exemple, entre 150 000 € et 200 000 €).</li>
<li>Non : Prix bas (par exemple, moins de 150 000 €).</li>
</ul></li>
</ol>
<p>Cet arbre utilise des règles simples pour diviser l’espace des caractéristiques (superficie et nombre de pièces) en sous-groupes homogènes et fournir une prédiction (estimer le prix d’une maison).</p>
<p><em>Figure illustrative</em></p>
</section>
</section>
<section id="lalgorithme-cart-un-partitionnement-binaire-récursif" class="level2">
<h2 class="anchored" data-anchor-id="lalgorithme-cart-un-partitionnement-binaire-récursif">L’algorithme CART, un partitionnement binaire récursif</h2>
<p>L’algorithme CART (Classification and Regression Trees) proposé par <span class="citation" data-cites="breiman1984cart">Breiman et al. (<a href="#ref-breiman1984cart" role="doc-biblioref">1984</a>)</span> est une méthode utilisée pour construire des arbres de décision, que ce soit pour des tâches de classification ou de régression. L’algorithme CART fonctionne en partitionnant l’espace des caractéristiques en sous-ensembles de manière récursive, en suivant une logique de décisions binaires à chaque étape. Ce processus est itératif et suit plusieurs étapes clés.</p>
<section id="définir-une-fonction-dimpureté-adaptée-au-problème" class="level3">
<h3 class="anchored" data-anchor-id="définir-une-fonction-dimpureté-adaptée-au-problème">Définir une fonction d’impureté adaptée au problème</h3>
<p>La <strong>fonction d’impureté</strong> est une mesure locale utilisée dans la construction des arbres de décision pour évaluer la qualité des divisions à chaque nœud. Elle quantifie le degré d’hétérogénéité des observations dans un nœud par rapport à la variable cible (classe pour la classification, ou valeur continue pour la régression). Plus précisément, une mesure d’impureté est conçue pour croître avec la dispersion dans un nœud. Un nœud est dit <strong>pur</strong> lorsque toutes les observations qu’il contient appartiennent à la même classe (classification) ou présentent des valeurs similaires/identiques (régression).</p>
<p>L’algorithme CART utilise ce type de mesure pour choisir les divisions qui créent des sous-ensembles plus homogènes que le nœud parent. À chaque étape de construction, l’algorithme sélectionne la division qui réduit le plus l’impureté, afin de garantir des nœuds de plus en plus homogènes au fur et à mesure que l’arbre se développe.</p>
<p>Le choix de la fonction d’impureté dépend du type de problème :</p>
<ul>
<li><p><strong>Classification</strong> : L’<strong>indice de Gini</strong> ou l’<strong>entropie</strong> sont très souvent utilisées pour évaluer la dispersion des classes dans chaque nœud.</p></li>
<li><p><strong>Régression</strong> : La <strong>somme des erreurs quadratiques</strong> (SSE) est souvent utilisée pour mesurer la variance des valeurs cibles dans chaque nœud.</p></li>
</ul>
<section id="mesures-dimpureté-classiques-pour-les-problèmes-de-classification" class="level4">
<h4 class="anchored" data-anchor-id="mesures-dimpureté-classiques-pour-les-problèmes-de-classification">Mesures d’impureté classiques pour les problèmes de classification</h4>
<p>Dans le cadre de la classification, l’objectif est de partitionner les données de manière à ce que chaque sous-ensemble (ou région) soit le plus homogène possible en termes de classe prédite. Plusieurs mesures d’impureté sont couramment utilisées pour évaluer la qualité des divisions.</p>
<p><strong>Propriété-définition d’une mesure d’impureté</strong></p>
<p>Pour un nœud <span class="math inline">\(t\)</span> contenant <span class="math inline">\(K\)</span> classes, une <strong>mesure d’impureté</strong> <span class="math inline">\(I(t)\)</span> est une fonction qui quantifie l’hétérogénéité des classes dans ce nœud. Elle doit satisfaire les propriétés suivantes :</p>
<ul>
<li><p><strong>Pureté maximale</strong> : Lorsque toutes les observations du nœud appartiennent à une seule classe, c’est-à-dire que la proportion <span class="math inline">\(p_k = 1\)</span> pour une classe <span class="math inline">\(k\)</span> et <span class="math inline">\(p_j = 0\)</span> pour toutes les autres classes <span class="math inline">\(j \neq k\)</span>, l’impureté est minimale et <span class="math inline">\(I(t) = 0\)</span>. Cela indique que le nœud est <strong>entièrement pur</strong>, ou homogène.</p></li>
<li><p><strong>Impureté maximale</strong> : Lorsque les observations sont réparties de manière uniforme entre toutes les classes, c’est-à-dire que <span class="math inline">\(p_k = \frac{1}{K}\)</span> pour chaque classe <span class="math inline">\(k\)</span>, l’impureté atteint son maximum. Cette situation reflète une <strong>impureté élevée</strong>, car le nœud est très hétérogène et contient une forte incertitude sur la classe des observations.</p></li>
</ul>
<p><strong>1. L’indice de Gini</strong></p>
<p>L’<strong>indice de Gini</strong> est l’une des fonctions de perte les plus couramment utilisées pour la classification. Il mesure la probabilité qu’un individu sélectionné au hasard dans un nœud soit mal classé si on lui attribue une classe au hasard, en fonction de la distribution des classes dans ce nœud.</p>
<p>Pour un nœud <span class="math inline">\(t\)</span> contenant <span class="math inline">\(K\)</span> classes, l’indice de Gini <span class="math inline">\(G(t)\)</span> est donné par :</p>
<p><span class="math display">\[
G(t) = 1 - \sum_{k=1}^{K} p_k^2
\]</span></p>
<p>où <span class="math inline">\(p_k\)</span> est la proportion d’observations appartenant à la classe <span class="math inline">\(k\)</span> dans le nœud <span class="math inline">\(t\)</span>.</p>
<!-- **Propriété** :

- Lorsque toutes les observations appartiennent à une même classe, $p_k = 1$ pour cette classe et $G(t) = 0$, ce qui signifie que le nœud est **pur**.

- À l'inverse, lorsque les observations sont également réparties entre les classes, $p_k$ tend vers des valeurs égales pour chaque classe, et $G(t)$ atteint son maximum, indiquant une **impureté élevée**.-->
<p><strong>Critère de choix</strong> : L’indice de Gini est souvent utilisé parce qu’il est simple à calculer et capture bien l’homogénéité des classes au sein d’un nœud. Il privilégie les partitions où une classe domine fortement dans chaque sous-ensemble.</p>
<p><strong>2. L’entropie (ou entropie de Shannon)</strong></p>
<p>L’<strong>entropie</strong> est une autre mesure de l’impureté utilisée dans les arbres de décision. Elle mesure la quantité d’incertitude ou de désordre dans un nœud, en s’appuyant sur la théorie de l’information.</p>
<p>Pour un nœud <span class="math inline">\(t\)</span> contenant <span class="math inline">\(K\)</span> classes, l’entropie <span class="math inline">\(E(t)\)</span> est définie par :</p>
<p><span class="math display">\[
E(t) = - \sum_{k=1}^{K} p_k \log(p_k)
\]</span></p>
<p>où <span class="math inline">\(p_k\)</span> est la proportion d’observations de la classe <span class="math inline">\(k\)</span> dans le nœud <span class="math inline">\(t\)</span>.</p>
<!-- **Propriété** :

- Comme pour l'indice de Gini, si toutes les observations d'un nœud appartiennent à la même classe, l'entropie est nulle ($E(t) = 0$), indiquant un nœud pur.

- L'entropie atteint son maximum lorsque les observations sont uniformément réparties entre les classes, reflétant une grande incertitude dans la classification.-->
<p><strong>Critère de choix</strong> : L’entropie a tendance à être plus sensible aux changements dans les distributions des classes que l’indice de Gini, car elle attribut un poids plus élevé aux événements rares (valeurs de <span class="math inline">\(p_k\)</span> très faibles). Elle est souvent utilisée lorsque l’erreur de classification des classes minoritaires est particulièrement importante.</p>
<p><strong>3. Taux d’erreur</strong></p>
<p>Le <strong>taux d’erreur</strong> est une autre mesure de l’impureté parfois utilisée dans les arbres de décision. Il représente la proportion d’observations mal classées dans un nœud.</p>
<p>Pour un nœud <span class="math inline">\(t\)</span>, le taux d’erreur <span class="math inline">\(\text{TE}(t)\)</span> est donné par :</p>
<p><span class="math display">\[
\text{TE}(t) = 1 - \max(p_k)
\]</span></p>
<p>où <span class="math inline">\(\max(p_k)\)</span> est la proportion d’observations appartenant à la classe majoritaire dans le nœud.</p>
<!-- **Propriété** :

- Si toutes les observations d'un nœud appartiennent à la même classe, le taux d'erreur est nul ($\text{TE}(t) = 0$), indiquant un nœud pur.

- Le taux d'erreur atteint son maximum lorsque les observations sont uniformément réparties entre les classes, reflétant une grande incertitude dans la classification.-->
<p><strong>Critère de choix</strong> : Bien que le taux d’erreur soit simple à comprendre, il est moins souvent utilisé dans la construction des arbres de décision parce qu’il est moins sensible que l’indice de Gini ou l’entropie aux petits changements dans la distribution des classes.</p>
</section>
<section id="mesures-dimpureté-classiques-pour-les-problèmes-de-régression" class="level4">
<h4 class="anchored" data-anchor-id="mesures-dimpureté-classiques-pour-les-problèmes-de-régression">Mesures d’impureté classiques pour les problèmes de régression</h4>
<p>Dans les problèmes de régression, l’objectif est de partitionner les données de manière à réduire au maximum la variabilité des valeurs au sein de chaque sous-ensemble. Pour mesurer cette variabilité, la somme des erreurs quadratiques (SSE) est la fonction d’impureté la plus couramment employée. Elle évalue l’impureté d’une région en quantifiant à quel point les valeurs de cette région s’écartent de la moyenne locale.</p>
<p><strong>1.Somme des erreurs quadratiques (SSE) ou variance</strong></p>
<p>La <strong>somme des erreurs quadratiques</strong> (ou <strong>SSE</strong>, pour <em>Sum of Squared Errors</em>) est une mesure qui quantifie la dispersion des valeurs dans un nœud par rapport à la moyenne des valeurs dans ce nœud.</p>
<p><strong>Formule</strong> : Pour un nœud <span class="math inline">\(t\)</span>, contenant <span class="math inline">\(N\)</span> observations avec des valeurs <span class="math inline">\(y_i\)</span>, la SSE est donnée par :</p>
<p><span class="math display">\[
\text{SSE}(t) = \sum_{i=1}^{N} (y_i - \hat{y})^2
\]</span></p>
<p>où <span class="math inline">\(\hat{y}\)</span> est la moyenne des valeurs <span class="math inline">\(y_i\)</span> dans le nœud <span class="math inline">\(t\)</span>.</p>
<p><strong>Propriété</strong> :</p>
<ul>
<li><p>Si toutes les valeurs de <span class="math inline">\(y_i\)</span> dans un nœud sont proches de la moyenne <span class="math inline">\(\hat{y}\)</span>, la SSE sera faible, indiquant une homogénéité élevée dans le nœud.</p></li>
<li><p>En revanche, une SSE élevée indique une grande variabilité dans les valeurs, donc un nœud impur.</p></li>
</ul>
<p><strong>Critère de choix</strong> : La somme des erreurs quadratiques (SSE) est particulièrement sensible aux écarts élevés entre les valeurs observées et la moyenne prédite. En cherchant à minimiser la SSE, les modèles visent à former des nœuds dans lesquels les valeurs des observations sont aussi proches que possible de la moyenne locale.</p>
</section>
</section>
<section id="identifier-la-partition-binaire-maximisant-la-réduction-de-limpureté" class="level3">
<h3 class="anchored" data-anchor-id="identifier-la-partition-binaire-maximisant-la-réduction-de-limpureté">Identifier la partition binaire maximisant la réduction de l’impureté</h3>
<p>Une fois la mesure d’impureté définie, l’algorithme CART examine toutes les divisions binaires possibles de l’espace des caractéristiques. À chaque nœud, et pour chaque caractéristique, il cherche à identifier le <strong>seuil optimal</strong>, c’est-à-dire le seuil qui minimise le plus efficacement l’impureté des deux sous-ensembles générés. L’algorithme compare ensuite toutes les divisions potentielles (caractéristiques et seuils optimaux associés à chaque nœud) et sélectionne celle qui entraîne la réduction maximale de l’impureté.</p>
<p>Prenons l’exemple d’une caractéristique continue, telle que la superficie d’une maison :</p>
<ul>
<li><p>Si l’algorithme teste la règle “Superficie &gt; 100 m²”, il calcule la fonction de perte pour les deux sous-ensembles générés par cette règle (“Oui” et “Non”).</p></li>
<li><p>Ce processus est répété pour différentes valeurs seuils afin de trouver la partition qui minimise le plus efficacement l’impureté au sein des sous-ensembles.</p></li>
</ul>
</section>
<section id="réitérer-le-processus-jusquà-atteindre-un-critère-darrêt" class="level3">
<h3 class="anchored" data-anchor-id="réitérer-le-processus-jusquà-atteindre-un-critère-darrêt">Réitérer le processus jusqu’à atteindre un critère d’arrêt</h3>
<p>L’algorithme CART poursuit le partitionnement de l’espace des caractéristiques en appliquant de manière récursive les mêmes étapes : identification de la caractéristique et du seuil optimal pour chaque nœud, puis sélection du partitionnement binaire qui maximise la réduction de l’impureté. Ce processus est répété jusqu’à ce qu’un <strong>critère d’arrêt</strong> soit atteint, par exemple :</p>
<ul>
<li><strong>Profondeur maximale de l’arbre</strong> : Limiter le nombre de divisions successives pour éviter un arbre trop complexe.</li>
<li><strong>Nombre minimum d’observations par feuille</strong> : Empêcher la création de feuilles contenant très peu d’observations, ce qui réduirait la capacité du modèle à généraliser.</li>
<li><strong>Réduction minimale de l’impureté à chaque étape</strong></li>
</ul>
</section>
<section id="elagage-pruning" class="level3">
<h3 class="anchored" data-anchor-id="elagage-pruning">Elagage (<em>pruning</em>)</h3>
</section>
<section id="prédire" class="level3">
<h3 class="anchored" data-anchor-id="prédire">Prédire</h3>
<p>Une fois l’arbre construit, la prédiction pour une nouvelle observation s’effectue en suivant les branches de l’arbre, en partant du nœud racine jusqu’à un nœud terminal (ou feuille). À chaque nœud interne, une décision est prise en fonction des valeurs des caractéristiques de l’observation, ce qui détermine la direction à suivre vers l’un des sous-ensembles. Ce cheminement se poursuit jusqu’à ce que l’observation atteigne une feuille, où la prédiction finale est effectuée.</p>
<ul>
<li>En <strong>classification</strong>, la classe attribuée est celle majoritaire dans la feuille atteinte.</li>
<li>En <strong>régression</strong>, la valeur prédite est généralement la moyenne des valeurs cibles des observations dans la feuille.</li>
</ul>
</section>
<section id="critères-de-qualité-et-ajustements" class="level3">
<h3 class="anchored" data-anchor-id="critères-de-qualité-et-ajustements">Critères de qualité et ajustements</h3>
<p>Pour améliorer la performance de l’arbre, on peut ajuster les hyperparamètres tels que la profondeur maximale ou le nombre minimum d’observations dans une feuille. De plus, des techniques comme la <strong>prédiction avec arbres multiples</strong> (bagging, forêts aléatoires) permettent de surmonter les limites des arbres individuels, souvent sujets au surapprentissage.</p>
</section>
</section>
<section id="avantages-et-limites-de-cette-approche" class="level2">
<h2 class="anchored" data-anchor-id="avantages-et-limites-de-cette-approche">Avantages et limites de cette approche</h2>
<section id="avantages" class="level3">
<h3 class="anchored" data-anchor-id="avantages">Avantages</h3>
<ul>
<li><strong>Interprétabilité</strong> : Les arbres de décision sont faciles à comprendre et à visualiser.</li>
<li><strong>Simplicité</strong> : Pas besoin de transformations complexes des données.</li>
<li><strong>Flexibilité</strong> : Ils peuvent gérer des caractéristiques numériques et catégorielles, ainsi que les valeurs manquantes.</li>
<li><strong>Gestion des interactions</strong> : Modèles non paramétriques, pas d’hypothèses sur les lois par les variables. Ils capturent naturellement les interactions entre les caractéristiques.</li>
</ul>
</section>
<section id="limites" class="level3">
<h3 class="anchored" data-anchor-id="limites">Limites</h3>
<ul>
<li><strong>Surapprentissage</strong> : Les arbres trop profonds peuvent surapprendre les données d’entraînement.</li>
<li><strong>Optimisation locale</strong> : L’approche gloutonne peut conduire à des solutions sous-optimales globalement (optimum local).</li>
<li><strong>Stabilité</strong> : De petits changements dans les données peuvent entraîner des changements significatifs dans la structure de l’arbre (manque de robustesse).</li>
</ul>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-breiman1984cart" class="csl-entry" role="listitem">
Breiman, Leo, Jerome Friedman, Richard Olshen, and Charles Stone. 1984. <span>“Cart.”</span> <em>Classification and Regression Trees</em>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/github\.com\/oliviermeslin\/DT_methodes_ensemblistes");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter2/0-intro.html" class="pagination-link" aria-label="Présentation formelle des algorithmes">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Présentation formelle des algorithmes</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter2/2-bagging.html" class="pagination-link" aria-label="Le bagging">
        <span class="nav-page-text">Le bagging</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© CC-1.0</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/oliviermeslin/DT_methodes_ensemblistes/edit/main/chapters/chapter2/1-CART.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/oliviermeslin/DT_methodes_ensemblistes/blob/main/chapters/chapter2/1-CART.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/oliviermeslin/DT_methodes_ensemblistes/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>